# **Procesamiento de Logs con Hadoop** üìä
![Hadoop Logo](https://github.com/user-attachments/assets/e7461ddc-c9a4-4589-87be-eda411201820)


## **Objetivo** üìù

El proyecto consiste en el procesamiento distribuido de un archivo de logs (`access.log`) utilizando **Hadoop**. El objetivo es analizar el archivo para identificar la presencia de palabras clave:

- `"GET /image"`
- `"POST"`
- `"error"`

---
## **¬øPor qu√© decid√≠ usar Hadoop?** ‚úÖ

Aunque tanto **Hadoop** como **Spark** nos permiten hacer procesamiento distribuido de grandes vol√∫menes de datos, decid√≠ utilizar **Hadoop** por las siguientes razones:
   - Poder trabajar con archivos comprimidos como `.bzip2`. Permite procesar estos formatos sin necesidad de descomprimirlos manualmente y teniendo un peso mucho menor, lo que mejora la eficiencia.
   - Utilizar **MapReduce**, que como vimos es muy √∫til para procesamiento de datos en lotes. Sumado a que disponiamos de un JAR preparado para realizar el conteo de las palabras.

En resumen, Hadoop fue la elecci√≥n m√°s adecuada para este proyecto debido a su compatibilidad con archivos comprimidos, su enfoque en el procesamiento en lotes y su facilidad para realizarse.

---
## **Proceso ETL** üîß

El proyecto sigue un proceso **ETL** :

### **1.Extracci√≥n** üì§
En esta etapa, se obtiene el archivo de logs (`access.log`) desde su fuente en un bucket de S3 en AWS. Dado que los logs eran de gran tama√±o, se utiliz√≥ el script `convertir.py` para comprimirlos en formato `.bzip2`. Esto reduce el espacio de almacenamiento, facilita su transferencia y procesamiento en Hadoop.
> **Nota:** El archivo comprimido (`access.log.bz2`) se copio al sistema de archivos distribuido de Hadoop (HDFS) üñ•Ô∏è
### **2.Transformaci√≥n** üîÑ
Una vez que los datos est√°n en HDFS, se ejecuta un JAR de WORDCOUNT para procesar el archivo comprimido. En este paso se realizaron las siguientes transformaciones:
- **Filtrado:** Se buscan las veces que se presentan los terminos clave `"GET /image"`, `"POST"` y `"error"` dentro del archivo de logs.
- **Conteo:** Se cuentan las apariciones de cada t√©rmino para generar estad√≠sticas √∫tiles.
### **3.Carga** üì•
Finalmente, los resultados del procesamiento se almacenan nuevamente en HDFS en un archivo de texto. Estos datos pueden ser utilizados para generar reportes como este informes.

---

## **Pasos del Proyecto** üõ†Ô∏è

### **1. Carga del Archivo `access.log` a un Bucket en AWS S3** 

El primer paso fue cargar el archivo de logs (`access.log`) en un bucket de **AWS S3**.

### **2. Compresi√≥n a Bzip2 de los Logs con `convertir.py`** 

Para procesar los logs, utilic√© un script en Python (`convertir.py`) utilizando la biblioteca `boto3`,`zipfile` y `bz2`:

### **3. Conexi√≥n a la Instancia Master del Cluster EMR** üíª

Me conect√© a la instancia **master** utilizando **EC2 Instance Connect**.
### **4. Transferencia del Archivo desde S3 a una Carpeta Local en el Cluster** üìÇ

Una vez conectado al cluster EMR, transfer√≠ el archivo comprimido (`access.log.bz2`) desde el bucket de S3 a una carpeta local llamada `input` en HDFS. 

  ```aws s3 cp s3://proyecto-final-spark-hadoop-data-engineer/compressed/access.log.bz2```
  
  ```hdfs dfs -put access.log.bz2 /input/```

  Comprobamos que esta el archivo usando

  ```hdfs dfs -ls /input```
### **5. Ejecuci√≥n del Procesamiento con Hadoop** üöÄ

El √∫ltimo paso consisti√≥ en ejecutar jobs de MapReduce utilizando Hadoop para analizar el archivo `access.log.bz2` y extraer las ocurrencias de los t√©rminos `"GET /image"`, `"POST"` y `"error"`. Estos comandos se ejecutaron directamente en la terminal del cluster EMR.

- Para buscar y contar las ocurrencias del t√©rmino `"GET /image"`, utilic√© el siguiente comando:
  ```
  hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar grep input/access.log.bz2 proyecto_logs/salida_get_image "GET /image"
  hdfs dfs -cat proyecto_logs/salida_get_image/part-r-00000
- Para buscar y contar las ocurrencias del t√©rmino "POST", utilic√© el siguiente comando:
  ```
  hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar grep input/access.log.bz2 proyecto_logs/salida_post "POST"
  hdfs dfs -cat proyecto_logs/salida_post/part-r-00000
- Finalmente, para buscar y contar las ocurrencias del t√©rmino "error", utilic√© el siguiente comando:
  ```
  hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar grep input/access.log.bz2 proyecto_logs/salida_error "error"
  hdfs dfs -cat proyecto_logs/salida_error/part-r-00000
  
## **Resultados** üìà

Una vez completado el procesamiento de los logs utilizando **Hadoop**, se obtuvieron los siguientes resultados:

| **T√©rmino**       | **Ocurrencias** |
|--------------------|-----------------|
| `"GET /image"`     | 5,682,613       |
| `"POST"`           | 139,155         |
| `"error"`          | 27,678          |
